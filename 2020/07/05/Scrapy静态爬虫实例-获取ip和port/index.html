<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/pain.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/pain.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/pain.jpg?v=5.1.4">


  <link rel="mask-icon" href="/images/pain.jpg?v=5.1.4" color="#222">





  <meta name="keywords" content="Python,Scrapy,静态爬虫," />










<meta name="description" content="地址：https:&#x2F;&#x2F;www.xicidaili.com&#x2F;nn&#x2F; 1新建项目scrapy startproject xxx(项目名称) 1D:\pycode&gt;scrapy startproject xicidailiSpider  2 创建爬虫scrapy genspider 爬虫名称 域名 1D:\pycode\xicidailiSpider&gt;scrapy genspider xic">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy静态爬虫实例-爬取ip和port">
<meta property="og:url" content="http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/index.html">
<meta property="og:site_name" content="Eve&#39;s Blog">
<meta property="og:description" content="地址：https:&#x2F;&#x2F;www.xicidaili.com&#x2F;nn&#x2F; 1新建项目scrapy startproject xxx(项目名称) 1D:\pycode&gt;scrapy startproject xicidailiSpider  2 创建爬虫scrapy genspider 爬虫名称 域名 1D:\pycode\xicidailiSpider&gt;scrapy genspider xic">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/Scrapy-%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport%5C1.png">
<meta property="og:image" content="http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/Scrapy-%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport%5C2.png">
<meta property="article:published_time" content="2020-07-05T14:41:15.000Z">
<meta property="article:modified_time" content="2020-07-06T15:54:28.044Z">
<meta property="article:author" content="Eve-Wang">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Scrapy">
<meta property="article:tag" content="静态爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/Scrapy-%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport%5C1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/07/05/Scrapy静态爬虫实例-获取ip和port/"/>





  <title>Scrapy静态爬虫实例-爬取ip和port | Eve's Blog</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Eve's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Eve-Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/pain.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eve's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Scrapy静态爬虫实例-爬取ip和port</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-05T22:41:15+08:00">
                2020-07-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%88%AC%E8%99%AB/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>地址：<a href="https://www.xicidaili.com/nn/" target="_blank" rel="noopener">https://www.xicidaili.com/nn/</a></p>
<h2 id="1新建项目"><a href="#1新建项目" class="headerlink" title="1新建项目"></a>1新建项目</h2><p>scrapy startproject xxx(项目名称)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\pycode&gt;scrapy startproject xicidailiSpider</span><br></pre></td></tr></table></figure>

<h2 id="2-创建爬虫"><a href="#2-创建爬虫" class="headerlink" title="2 创建爬虫"></a>2 创建爬虫</h2><p>scrapy genspider 爬虫名称 域名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\pycode\xicidailiSpider&gt;scrapy genspider xicidaili xicidaili.com</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>   *上面是项目名称，下面是爬虫名称，不要弄成一样的了。</p>
<p>   *网站域名是允许爬虫采集的域名</p>
<p>打开项目，我们就可以发现spider文件夹下有xicidaili.py文件了，这就是我们的爬虫文件！！！</p>
<h2 id="3-Robots协议"><a href="#3-Robots协议" class="headerlink" title="3 Robots协议"></a>3 Robots协议</h2><p>在settings.py文件中，找到下面这行代码</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">True</span></span><br></pre></td></tr></table></figure>

<p>将True改为False： 不然爬虫没法工作</p>
<p>可以到网站根目录添加后缀 robots.txt查看网站的robots协议</p>
<h2 id="4-爬虫文件介绍"><a href="#4-爬虫文件介绍" class="headerlink" title="4 爬虫文件介绍"></a>4 爬虫文件介绍</h2><p>打开xicidaili.py文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy   <span class="comment">#导入scrapy包</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建爬虫类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XicidailiSpider</span><span class="params">(scrapy.Spider)</span>:</span>  <span class="comment">#继承自scrapy.Spider类</span></span><br><span class="line">    name = <span class="string">'xicidaili'</span>   <span class="comment">#爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">'xicidaili.com'</span>] <span class="comment">#允许爬取的域名，可以注释掉</span></span><br><span class="line">    start_urls = [<span class="string">'http://xicidaili.com/'</span>] <span class="comment">#开始采集的网址</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#解析响应数据，提取数据获取网址等  response就是网页源码</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="5分析网站"><a href="#5分析网站" class="headerlink" title="5分析网站"></a>5分析网站</h2><ul>
<li>提取数据<ul>
<li>正则（基础  ）</li>
<li>xpath ——–&gt;从html中提取数据语法<ul>
<li>response.xpath(‘xpath表达式’).get()  获取一个数据</li>
<li>response.xpath(‘xpath表达式’).getall()  获取多个数据</li>
<li>response.xpath(‘xpath表达式’).extract_first()  和get同样的效果</li>
<li>用xpath helper这个插件，我们可以直观的去查找标签</li>
</ul>
</li>
<li>css</li>
<li>BS4 </li>
</ul>
</li>
</ul>
<h2 id="6提取数据"><a href="#6提取数据" class="headerlink" title="6提取数据"></a>6提取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy   <span class="comment">#导入scrapy包</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建爬虫类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XicidailiSpider</span><span class="params">(scrapy.Spider)</span>:</span>  <span class="comment">#继承自scrapy.Spider类</span></span><br><span class="line">    name = <span class="string">'xicidaili'</span>   <span class="comment">#爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">'xicidaili.com'</span>] <span class="comment">#允许爬取的域名，可以注释掉</span></span><br><span class="line">    <span class="comment"># start_urls = ['http://xicidaili.com/'] #开始采集的网址</span></span><br><span class="line">    start_urls = [<span class="string">'https://www.xicidaili.com/nn/'</span>]<span class="comment">#浏览器打开把网址复制下来</span></span><br><span class="line"><span class="comment">#解析响应数据，提取数据获取网址等  response就是网页源码</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment">#提取ip,port</span></span><br><span class="line">        <span class="comment"># response.xpath('表达式')</span></span><br><span class="line">        <span class="comment"># response.xpath('//tr//td[2]/text()')  #ip</span></span><br><span class="line">        <span class="comment"># response.xpath('//tr//td[3]/text()')  #port</span></span><br><span class="line">        <span class="comment"># 我们不像上面几行这么写，拿到tr标签的内容再选择可以保证每个ip和它的port一一对应</span></span><br><span class="line">        selectors = response.xpath(<span class="string">'//tr'</span>)   <span class="comment">#选择所有的tr标签</span></span><br><span class="line">        <span class="keyword">for</span> selector <span class="keyword">in</span> selectors:  <span class="comment">#遍历tr标签下的所有的td标签</span></span><br><span class="line">            ip = selector.xpath(<span class="string">'./td[2]/text()'</span>)  <span class="comment">#   ./ 表示在当前节点下继续选择</span></span><br><span class="line">            port = selector.xpath(<span class="string">'./td[3]/text()'</span>) <span class="comment">#在当前节点下继续选择</span></span><br><span class="line"></span><br><span class="line">            print(ip,port)  <span class="comment">#打印ip  port</span></span><br></pre></td></tr></table></figure>

<h2 id="7运行爬虫"><a href="#7运行爬虫" class="headerlink" title="7运行爬虫"></a>7运行爬虫</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\pycode\xicidailiSpider&gt;scrapy crawl xicidaili</span><br></pre></td></tr></table></figure>

<p>发现报错了：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">2019-09-15 20:22:36 [scrapy.utils.log] INFO: Scrapy 1.7.2 started (bot: xicidailiSpider)</span><br><span class="line">2019-09-15 20:22:36 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.17134-SP0</span><br><span class="line">2019-09-15 20:22:36 [scrapy.crawler] INFO: Overridden settings: &#123;'BOT_NAME': 'xicidailiSpider', 'NEWSPIDER_MODULE': 'xicidailiSpider.spiders', 'SPIDER_MODULES': ['xicidailiSpider.spiders']&#125;</span><br><span class="line">2019-09-15 20:22:36 [scrapy.extensions.telnet] INFO: Telnet Password: 1f33d178e985a6c0</span><br><span class="line">2019-09-15 20:22:36 [scrapy.middleware] INFO: Enabled extensions:</span><br><span class="line">['scrapy.extensions.corestats.CoreStats',</span><br><span class="line"> 'scrapy.extensions.telnet.TelnetConsole',</span><br><span class="line"> 'scrapy.extensions.logstats.LogStats']</span><br><span class="line">2019-09-15 20:22:36 [scrapy.middleware] INFO: Enabled downloader middlewares:</span><br><span class="line">['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.retry.RetryMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',</span><br><span class="line"> 'scrapy.downloadermiddlewares.stats.DownloaderStats']</span><br><span class="line">2019-09-15 20:22:36 [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',</span><br><span class="line"> 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',</span><br><span class="line"> 'scrapy.spidermiddlewares.referer.RefererMiddleware',</span><br><span class="line"> 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',</span><br><span class="line"> 'scrapy.spidermiddlewares.depth.DepthMiddleware']</span><br><span class="line">2019-09-15 20:22:36 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[]</span><br><span class="line">2019-09-15 20:22:36 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2019-09-15 20:22:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</span><br><span class="line">2019-09-15 20:22:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2019-09-15 20:22:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying &lt;GET https://www.xicidaili.com/nn/&gt; (failed 1 times): 503 Service Unavailable</span><br><span class="line">2019-09-15 20:22:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying &lt;GET https://www.xicidaili.com/nn/&gt; (failed 2 times): 503 Service Unavailable</span><br><span class="line">2019-09-15 20:22:37 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying &lt;GET https://www.xicidaili.com/nn/&gt; (failed 3 times): 503 Service Unavailable</span><br><span class="line">2019-09-15 20:22:37 [scrapy.core.engine] DEBUG: Crawled (503) &lt;GET https://www.xicidaili.com/nn/&gt; (referer: None)</span><br><span class="line">2019-09-15 20:22:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response &lt;503 https://www.xicidaili.com/nn/&gt;: HTTP status code is not handled or not allowed</span><br><span class="line">2019-09-15 20:22:37 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">2019-09-15 20:22:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;'downloader/request_bytes': 657,</span><br><span class="line"> 'downloader/request_count': 3,</span><br><span class="line"> 'downloader/request_method_count/GET': 3,</span><br><span class="line"> 'downloader/response_bytes': 999,</span><br><span class="line"> 'downloader/response_count': 3,</span><br><span class="line"> 'downloader/response_status_count/503': 3,</span><br><span class="line"> 'elapsed_time_seconds': 0.60528,</span><br><span class="line"> 'finish_reason': 'finished',</span><br><span class="line"> 'finish_time': datetime.datetime(2019, 9, 15, 12, 22, 37, 561550),</span><br><span class="line"> 'httperror/response_ignored_count': 1,</span><br><span class="line"> 'httperror/response_ignored_status_count/503': 1,</span><br><span class="line"> 'log_count/DEBUG': 4,</span><br><span class="line"> 'log_count/INFO': 11,</span><br><span class="line"> 'response_received_count': 1,</span><br><span class="line"> 'retry/count': 2,</span><br><span class="line"> 'retry/max_reached': 1,</span><br><span class="line"> 'retry/reason_count/503 Service Unavailable': 2,</span><br><span class="line"> 'scheduler/dequeued': 3,</span><br><span class="line"> 'scheduler/dequeued/memory': 3,</span><br><span class="line"> 'scheduler/enqueued': 3,</span><br><span class="line"> 'scheduler/enqueued/memory': 3,</span><br><span class="line"> 'start_time': datetime.datetime(2019, 9, 15, 12, 22, 36, 956270)&#125;</span><br><span class="line">2019-09-15 20:22:37 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>

<p>503错误，服务器端的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">downloader&#x2F;response_status_count&#x2F;503&#39;: 3,</span><br></pre></td></tr></table></figure>

<p><strong>补充：常见可能被网站识别返回错误</strong><br> 1、CAPTCHApages （captcha，验证码）</p>
<p>2、Unusualcontent delivery delay  （响应时间、速度变慢了）</p>
<p>3、Frequentresponse with HTTP404,301 or 50x errors</p>
<p>（1）301 MovedTemporarily</p>
<p>（2）401unauthorized</p>
<p>（3）403forbidden  （aAatch处理的）</p>
<p>（4）404 notfound</p>
<p>（5）408 requesttimeout</p>
<p>（6）429 too manyrequests</p>
<p>（7）503 serviceunavailable  （ip层）</p>
<h2 id="8原因分析："><a href="#8原因分析：" class="headerlink" title="8原因分析："></a>8原因分析：</h2><p>1、在settings中将rebots改为False，发现依旧返回503错误</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Obey robots.txt rules</span><br><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br></pre></td></tr></table></figure>

<p>2、再分析，浏览器中打开正常显示，scrapy跟浏览器请求是同一个ip，所以排除ip封锁问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">网页不需要登录，排除cookie问题，剩下就是headers中user_agent的问题了。scrapy中添加user_agent之后，成功解决</span><br><span class="line"></span><br><span class="line">结论：没有请求头，被网站识别为爬虫程序（所以要模拟浏览器访问）</span><br></pre></td></tr></table></figure>

<p>所以我们要给他添加请求头header</p>
<h2 id="9添加头部"><a href="#9添加头部" class="headerlink" title="9添加头部"></a>9添加头部</h2><p>在settings.py文件里找到如下代码：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Override the default request headers:</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">  <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span>,</span><br><span class="line">  <span class="string">'Accept-Language'</span>: <span class="string">'en'</span>,</span><br><span class="line">  <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将其取消注释并添加请求头，运行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/text()' data='9999'&gt;]</span><br><span class="line">[<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[2]/text()'</span> <span class="attr">data</span>=<span class="string">'120.83.103.135'</span>&gt;</span>] [<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[3]/text()'</span> <span class="attr">data</span>=<span class="string">'9999'</span>&gt;</span>]</span><br><span class="line">[<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[2]/text()'</span> <span class="attr">data</span>=<span class="string">'120.83.122.28'</span>&gt;</span>] [<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[3]/text()'</span> <span class="attr">data</span>=<span class="string">'9999'</span>&gt;</span>]</span><br><span class="line">[<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[2]/text()'</span> <span class="attr">data</span>=<span class="string">'14.115.206.93'</span>&gt;</span>] [<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[3]/text()'</span> <span class="attr">data</span>=<span class="string">'61234'</span>&gt;</span>]</span><br><span class="line">[<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[2]/text()'</span> <span class="attr">data</span>=<span class="string">'125.123.122.206'</span>&gt;</span>] [<span class="tag">&lt;<span class="name">Selector</span> <span class="attr">xpath</span>=<span class="string">'./td[3]/text()'</span> <span class="attr">data</span>=<span class="string">'9999'</span>&gt;</span>]</span><br></pre></td></tr></table></figure>

<p>但是有一个问题，我们要的数据保存在一个对象里面，我们要把他取出来：</p>
<h2 id="10数据整理"><a href="#10数据整理" class="headerlink" title="10数据整理"></a>10数据整理</h2><p>我们使用get/extract_first/getall方法来获取数据对象里的数据，在这里get/extract_firs所取得的效果是一样的，随意使用，接下来我们继续完善我们的爬虫文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy   <span class="comment">#导入scrapy包</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建爬虫类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XicidailiSpider</span><span class="params">(scrapy.Spider)</span>:</span>  <span class="comment">#继承自scrapy.Spider类</span></span><br><span class="line">    name = <span class="string">'xicidaili'</span>   <span class="comment">#爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">'xicidaili.com'</span>] <span class="comment">#允许爬取的域名</span></span><br><span class="line">    <span class="comment"># start_urls = ['http://xicidaili.com/'] #开始采集的网址</span></span><br><span class="line">    start_urls = [<span class="string">'https://www.xicidaili.com/nn/'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#解析响应数据，提取数据获取网址等  response就是网页源码</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment">#提取ip,port</span></span><br><span class="line">        <span class="comment"># response.xpath('表达式')</span></span><br><span class="line">        <span class="comment"># response.xpath('//tr//td[2]/text()')  #ip</span></span><br><span class="line">        <span class="comment"># response.xpath('//tr//td[3]/text()')  #port</span></span><br><span class="line">        <span class="comment"># 我们不像上面几行这么写，拿到tr标签的内容再选择可以保证每个ip和它的port一一对应</span></span><br><span class="line">        selectors = response.xpath(<span class="string">'//tr'</span>)   <span class="comment">#选择所有的tr标签</span></span><br><span class="line">        <span class="keyword">for</span> selector <span class="keyword">in</span> selectors:  <span class="comment">#遍历tr标签下的所有的td标签</span></span><br><span class="line">            ip = selector.xpath(<span class="string">'./td[2]/text()'</span>).get()  <span class="comment">#   ./ 表示在当前节点下继续选择</span></span><br><span class="line">            port = selector.xpath(<span class="string">'./td[3]/text()'</span>).get() <span class="comment">#在当前节点下继续选择</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#ip = selector.xpath('./td[2]/text()').extract_first()    </span></span><br><span class="line">            <span class="comment">#port = selector.xpath('./td[3]/text()').extract_first() #这两行与前两行效果一样</span></span><br><span class="line">            print(ip,port)  <span class="comment">#打印ip  port</span></span><br></pre></td></tr></table></figure>

<p>运行爬虫：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\pycode\xicidailiSpider&gt;scrapy crawl xicidaili</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">112<span class="selector-class">.87</span><span class="selector-class">.71</span><span class="selector-class">.119</span> 9999</span><br><span class="line">144<span class="selector-class">.123</span><span class="selector-class">.68</span><span class="selector-class">.159</span> 9999</span><br><span class="line">110<span class="selector-class">.86</span><span class="selector-class">.136</span><span class="selector-class">.82</span> 9999</span><br><span class="line">110<span class="selector-class">.86</span><span class="selector-class">.136</span><span class="selector-class">.128</span> 9999</span><br><span class="line">171<span class="selector-class">.11</span><span class="selector-class">.178</span><span class="selector-class">.251</span> 9999</span><br><span class="line">120<span class="selector-class">.83</span><span class="selector-class">.105</span><span class="selector-class">.156</span> 9999</span><br><span class="line">171<span class="selector-class">.35</span><span class="selector-class">.149</span><span class="selector-class">.199</span> 9999</span><br><span class="line">125<span class="selector-class">.125</span><span class="selector-class">.131</span><span class="selector-class">.41</span> 9999</span><br><span class="line">120<span class="selector-class">.83</span><span class="selector-class">.102</span><span class="selector-class">.74</span> 9999</span><br><span class="line">1<span class="selector-class">.197</span><span class="selector-class">.203</span><span class="selector-class">.187</span> 9999</span><br><span class="line">120<span class="selector-class">.84</span><span class="selector-class">.100</span><span class="selector-class">.140</span> 808</span><br><span class="line">115<span class="selector-class">.207</span><span class="selector-class">.253</span><span class="selector-class">.27</span> 9999</span><br><span class="line">120<span class="selector-class">.83</span><span class="selector-class">.101</span><span class="selector-class">.77</span> 9999</span><br><span class="line">120<span class="selector-class">.83</span><span class="selector-class">.102</span><span class="selector-class">.181</span> 9999</span><br><span class="line">27<span class="selector-class">.43</span><span class="selector-class">.185</span><span class="selector-class">.13</span> 9999</span><br><span class="line">1<span class="selector-class">.197</span><span class="selector-class">.11</span><span class="selector-class">.20</span> 9999</span><br><span class="line">120<span class="selector-class">.83</span><span class="selector-class">.103</span><span class="selector-class">.135</span> 9999</span><br><span class="line">120<span class="selector-class">.83</span><span class="selector-class">.122</span><span class="selector-class">.28</span> 9999</span><br><span class="line">14<span class="selector-class">.115</span><span class="selector-class">.206</span><span class="selector-class">.93</span> 61234</span><br><span class="line">125<span class="selector-class">.123</span><span class="selector-class">.122</span><span class="selector-class">.206</span> 9999</span><br></pre></td></tr></table></figure>

<p>这样就拿到了我们想要的东西</p>
<h2 id="11-问题来了（获取所有页面）"><a href="#11-问题来了（获取所有页面）" class="headerlink" title="11 问题来了（获取所有页面）"></a>11 问题来了（获取所有页面）</h2><p>我们这里只获取到了一个页面的数据，但现实中我们要爬取的远不止一个页面的，拿xicidaili来说，他目前有4071页，我们从最初级的开始 使用for循环，遍历看看：</p>
<p>遍历所有页面：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start_urls = [<span class="string">'https://www.xicidaili.com/nn/&#123;page&#125;'</span> <span class="keyword">for</span> page in <span class="keyword">range</span>(<span class="number">1</span>,<span class="number">4071</span>)]</span><br></pre></td></tr></table></figure>

<p>（但不要轻易尝试上述代码，短时间操作太多次可能会被网址封掉IP）</p>
<p>假如以后该网站继续添加页面数，那怎么办？</p>
<p>我们发现每页代码都标明了下一页，最后一页的next_page为disable,为空，所以就好办了。</p>
<p>我们在第一页时使用xpath获取下一页的链接地址：(用插件：xpath helper)</p>
<figure class="highlight xpath"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//a[@class=<span class="string">"next_page"</span>]/@href</span><br></pre></td></tr></table></figure>

<p>上行指在有键值对为class=”next_page”的a标签中找键为href的值</p>
<p>显示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;nn&#x2F;2</span><br></pre></td></tr></table></figure>

<h3 id="完整的爬虫代码"><a href="#完整的爬虫代码" class="headerlink" title="完整的爬虫代码"></a>完整的爬虫代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy   <span class="comment">#导入scrapy包</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建爬虫类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XicidailiSpider</span><span class="params">(scrapy.Spider)</span>:</span>  <span class="comment">#继承自scrapy.Spider类</span></span><br><span class="line">    name = <span class="string">'xicidaili'</span>   <span class="comment">#爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">'xicidaili.com'</span>] <span class="comment">#允许爬取的域名</span></span><br><span class="line">    <span class="comment"># start_urls = ['http://xicidaili.com/'] #开始采集的网址</span></span><br><span class="line">    start_urls = [<span class="string">'https://www.xicidaili.com/nn/4068'</span>]<span class="comment">#尝试一下从4068页开始爬</span></span><br><span class="line">    <span class="comment"># start_urls = ['https://www.xicidaili.com/nn/&#123;page&#125;' for page in range(1,4071)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#解析响应数据，提取数据获取网址等  response就是网页源码</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment">#提取ip,port</span></span><br><span class="line">        <span class="comment"># response.xpath('表达式')</span></span><br><span class="line">        <span class="comment"># response.xpath('//tr//td[2]/text()')  #ip</span></span><br><span class="line">        <span class="comment"># response.xpath('//tr//td[3]/text()')  #port</span></span><br><span class="line">        <span class="comment"># 我们不像上面几行这么写，拿到tr标签的内容再选择可以保证每个ip和它的port一一对应</span></span><br><span class="line">        selectors = response.xpath(<span class="string">'//tr'</span>)   <span class="comment">#选择所有的tr标签</span></span><br><span class="line">        <span class="keyword">for</span> selector <span class="keyword">in</span> selectors:  <span class="comment">#遍历tr标签下的所有的td标签</span></span><br><span class="line">            ip = selector.xpath(<span class="string">'./td[2]/text()'</span>).get()  <span class="comment">#   ./ 表示在当前节点下继续选择</span></span><br><span class="line">            port = selector.xpath(<span class="string">'./td[3]/text()'</span>).get() </span><br><span class="line">            </span><br><span class="line">            items=&#123;</span><br><span class="line">            <span class="string">'ip'</span>:ip,</span><br><span class="line">            <span class="string">'port'</span>:port</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">yield</span> items <span class="comment">#我们定义一个字典相当于给两列数据起名，并用生成器生成，后面进行保存操作</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#翻页操作</span></span><br><span class="line">        next_page = response.xpath(<span class="string">'//a[@class="next_page"]/@href'</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            print(next_page)</span><br><span class="line">            <span class="comment">#拼接网址</span></span><br><span class="line">            <span class="comment"># next_url = "https://www.xicidaili.com"+next_page;与下一行代码效果一样</span></span><br><span class="line">            next_url = response.urljoin(next_page)<span class="comment">#next_page作为相对路径并入url</span></span><br><span class="line">            <span class="comment">#发出请求   Request callback是回调函数，将请求得到响应交给自己处理</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_url,callback=self.parse) <span class="comment">#生成器</span></span><br></pre></td></tr></table></figure>

<p>Request()发出请求，类似于requests.get()</p>
<p>callback 是将发出去的请求得到的响应交还给自己处理</p>
<h2 id="12保存输出"><a href="#12保存输出" class="headerlink" title="12保存输出"></a>12保存输出</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\pycode\xicidailiSpider&gt;scrapy crawl xicidaili -o ip.json  (json文件) &#x2F;ip.csv(csv文件)</span><br></pre></td></tr></table></figure>

<p>现在可以看到文件已经保存好了</p>
<p><img src="/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/Scrapy-%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport%5C1.png" alt></p>
<p>打开csv文件：</p>
<p><img src="/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/Scrapy-%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport%5C2.png" alt></p>
<p>成功！</p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Mi1k7ea
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/" title="Scrapy静态爬虫实例-爬取ip和port">http://yoursite.com/2020/07/05/Scrapy%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B-%E8%8E%B7%E5%8F%96ip%E5%92%8Cport/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明：</strong>
    本文为博主原创文章，未经博主允许不得转载。
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/Scrapy/" rel="tag"><i class="fa fa-tag"></i> Scrapy</a>
          
            <a href="/tags/%E9%9D%99%E6%80%81%E7%88%AC%E8%99%AB/" rel="tag"><i class="fa fa-tag"></i> 静态爬虫</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/05/Python%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="next" title="Python之数据结构学习笔记">
                <i class="fa fa-chevron-left"></i> Python之数据结构学习笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/07/05/Python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="prev" title="Python爬虫学习笔记">
                Python爬虫学习笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/pain.jpg"
                alt="Eve-Wang" />
            
              <p class="site-author-name" itemprop="name">Eve-Wang</p>
              <p class="site-description motion-element" itemprop="description">My blog</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/eve-wang" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1新建项目"><span class="nav-text">1新建项目</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-创建爬虫"><span class="nav-text">2 创建爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Robots协议"><span class="nav-text">3 Robots协议</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-爬虫文件介绍"><span class="nav-text">4 爬虫文件介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5分析网站"><span class="nav-text">5分析网站</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6提取数据"><span class="nav-text">6提取数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7运行爬虫"><span class="nav-text">7运行爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8原因分析："><span class="nav-text">8原因分析：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9添加头部"><span class="nav-text">9添加头部</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10数据整理"><span class="nav-text">10数据整理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-问题来了（获取所有页面）"><span class="nav-text">11 问题来了（获取所有页面）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#完整的爬虫代码"><span class="nav-text">完整的爬虫代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12保存输出"><span class="nav-text">12保存输出</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-smile-o"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Eve-Wang</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
