<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>机器学习之基础篇 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="机器学习（基础理论篇）https:&#x2F;&#x2F;www.coursera.org&#x2F;learn&#x2F;machine-learning&#x2F;home&#x2F;welcome 机器学习可分为监督学习和无监督学习 监督学习在监督学习中，我们已经被告知了什么是所谓的正确答案。即下面例子中的良性和恶性。 回归问题（预测连续的数值输出）例子：房屋价格预测  线性回归算法也就是根据已有的样本拟合一条直线，用线性方程（一次函数）表示（称为假">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习之基础篇">
<meta property="og:url" content="http://yoursite.com/2020/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="机器学习（基础理论篇）https:&#x2F;&#x2F;www.coursera.org&#x2F;learn&#x2F;machine-learning&#x2F;home&#x2F;welcome 机器学习可分为监督学习和无监督学习 监督学习在监督学习中，我们已经被告知了什么是所谓的正确答案。即下面例子中的良性和恶性。 回归问题（预测连续的数值输出）例子：房屋价格预测  线性回归算法也就是根据已有的样本拟合一条直线，用线性方程（一次函数）表示（称为假">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/.com//1.png">
<meta property="og:image" content="http://yoursite.com/.com//5.png">
<meta property="og:image" content="http://yoursite.com/.com//6.png">
<meta property="og:image" content="http://yoursite.com/.com//7.png">
<meta property="og:image" content="http://yoursite.com/.com//8.png">
<meta property="og:image" content="http://yoursite.com/.com//9.png">
<meta property="og:image" content="http://yoursite.com/.com//10.png">
<meta property="og:image" content="http://yoursite.com/.com//11.png">
<meta property="og:image" content="http://yoursite.com/.com//14.png">
<meta property="og:image" content="http://yoursite.com/.com//15.png">
<meta property="og:image" content="http://yoursite.com/.com//13.png">
<meta property="og:image" content="http://yoursite.com/.com//12.png">
<meta property="og:image" content="http://yoursite.com/.com//2.png">
<meta property="og:image" content="http://yoursite.com/.com//3.png">
<meta property="og:image" content="http://yoursite.com/.com//16.png">
<meta property="og:image" content="http://yoursite.com/.com//17.png">
<meta property="og:image" content="http://yoursite.com/.com//18.png">
<meta property="og:image" content="http://yoursite.com/.com//19.png">
<meta property="og:image" content="http://yoursite.com/.com//20.png">
<meta property="og:image" content="http://yoursite.com/.com//21.png">
<meta property="og:image" content="http://yoursite.com/.com//22.png">
<meta property="og:image" content="http://yoursite.com/.com//23.png">
<meta property="og:image" content="http://yoursite.com/.com//24.png">
<meta property="og:image" content="http://yoursite.com/.com//7.png">
<meta property="og:image" content="http://yoursite.com/.com//25.png">
<meta property="og:image" content="http://yoursite.com/.com//26.png">
<meta property="og:image" content="http://yoursite.com/.com//27.png">
<meta property="og:image" content="http://yoursite.com/.com//28.png">
<meta property="og:image" content="http://yoursite.com/.com//29.png">
<meta property="og:image" content="http://yoursite.com/.com//30.png">
<meta property="og:image" content="http://yoursite.com/.com//31.png">
<meta property="og:image" content="http://yoursite.com/.com//32.png">
<meta property="og:image" content="http://yoursite.com/.com//33.png">
<meta property="og:image" content="http://yoursite.com/.com//34.png">
<meta property="og:image" content="http://yoursite.com/.com//35.png">
<meta property="og:image" content="http://yoursite.com/.com//40.png">
<meta property="og:image" content="http://yoursite.com/.com//36.png">
<meta property="og:image" content="http://yoursite.com/.com//37.png">
<meta property="og:image" content="http://yoursite.com/.com//38.png">
<meta property="og:image" content="http://yoursite.com/.com//39.png">
<meta property="og:image" content="http://yoursite.com/.com//41.png">
<meta property="og:image" content="http://yoursite.com/.com//42.png">
<meta property="og:image" content="http://yoursite.com/.com//43.png">
<meta property="og:image" content="http://yoursite.com/.com//45.png">
<meta property="og:image" content="http://yoursite.com/.com//46.png">
<meta property="og:image" content="http://yoursite.com/.com//47.png">
<meta property="og:image" content="http://yoursite.com/.com//48.png">
<meta property="og:image" content="http://yoursite.com/.com//49.png">
<meta property="og:image" content="http://yoursite.com/.com//52.png">
<meta property="og:image" content="http://yoursite.com/.com//51.png">
<meta property="og:image" content="http://yoursite.com/.com//50.png">
<meta property="og:image" content="http://yoursite.com/.com//53.png">
<meta property="og:image" content="http://yoursite.com/.com//55.png">
<meta property="og:image" content="http://yoursite.com/.com//57.png">
<meta property="og:image" content="http://yoursite.com/.com//58.png">
<meta property="og:image" content="http://yoursite.com/.com//59.png">
<meta property="og:image" content="http://yoursite.com/.com//60.png">
<meta property="og:image" content="http://yoursite.com/.com//61.png">
<meta property="og:image" content="http://yoursite.com/.com//62.png">
<meta property="og:image" content="http://yoursite.com/.com//63.png">
<meta property="og:image" content="http://yoursite.com/.com//64.png">
<meta property="og:image" content="http://yoursite.com/.com//65.png">
<meta property="og:image" content="http://yoursite.com/.com//66.png">
<meta property="og:image" content="http://yoursite.com/.com//56.png">
<meta property="og:image" content="http://yoursite.com/.com//68.png">
<meta property="og:image" content="http://yoursite.com/.com//69.png">
<meta property="og:image" content="http://yoursite.com/.com//70.png">
<meta property="og:image" content="http://yoursite.com/.com//71.png">
<meta property="og:image" content="http://yoursite.com/.com//72.png">
<meta property="og:image" content="http://yoursite.com/.com//73.png">
<meta property="og:image" content="http://yoursite.com/.com//74.png">
<meta property="og:image" content="http://yoursite.com/.com//75.png">
<meta property="og:image" content="http://yoursite.com/.com//76.png">
<meta property="og:image" content="http://yoursite.com/.com//77.png">
<meta property="og:image" content="http://yoursite.com/.com//80.png">
<meta property="og:image" content="http://yoursite.com/.com//81.png">
<meta property="og:image" content="http://yoursite.com/.com//78.png">
<meta property="og:image" content="http://yoursite.com/.com//82.png">
<meta property="og:image" content="http://yoursite.com/.com//79.png">
<meta property="og:image" content="http://yoursite.com/.com//83.png">
<meta property="og:image" content="http://yoursite.com/.com//84.png">
<meta property="og:image" content="http://yoursite.com/.com//85.png">
<meta property="og:image" content="http://yoursite.com/.com//86.png">
<meta property="og:image" content="http://yoursite.com/.com//87.png">
<meta property="og:image" content="http://yoursite.com/.com//4.png">
<meta property="og:image" content="http://yoursite.com/.com//88.png">
<meta property="og:image" content="http://yoursite.com/.com//89.png">
<meta property="og:image" content="http://yoursite.com/.com//90.png">
<meta property="og:image" content="http://yoursite.com/.com//91.png">
<meta property="og:image" content="http://yoursite.com/.com//92.png">
<meta property="og:image" content="http://yoursite.com/.com//93.png">
<meta property="og:image" content="http://yoursite.com/.com//94.png">
<meta property="og:image" content="http://yoursite.com/.com//95.png">
<meta property="og:image" content="http://yoursite.com/.com//96.png">
<meta property="og:image" content="http://yoursite.com/.com//97.png">
<meta property="og:image" content="http://yoursite.com/.com//98.png">
<meta property="og:image" content="http://yoursite.com/.com//99.png">
<meta property="og:image" content="http://yoursite.com/.com//100.png">
<meta property="og:image" content="http://yoursite.com/.com//101.png">
<meta property="og:image" content="http://yoursite.com/.com//104.png">
<meta property="og:image" content="http://yoursite.com/.com//102.png">
<meta property="og:image" content="http://yoursite.com/.com//103.png">
<meta property="og:image" content="http://yoursite.com/.com//105.png">
<meta property="og:image" content="http://yoursite.com/.com//106.png">
<meta property="og:image" content="http://yoursite.com/.com//110.png">
<meta property="og:image" content="http://yoursite.com/.com//109.png">
<meta property="og:image" content="http://yoursite.com/.com//107.png">
<meta property="og:image" content="http://yoursite.com/.com//108.png">
<meta property="og:image" content="http://yoursite.com/.com//111.png">
<meta property="og:image" content="http://yoursite.com/.com//112.png">
<meta property="og:image" content="http://yoursite.com/.com//113.png">
<meta property="og:image" content="http://yoursite.com/.com//114.png">
<meta property="og:image" content="http://yoursite.com/.com//115.png">
<meta property="og:image" content="http://yoursite.com/.com//116.png">
<meta property="og:image" content="http://yoursite.com/.com//117.png">
<meta property="og:image" content="http://yoursite.com/.com//118.png">
<meta property="og:image" content="http://yoursite.com/.com//119.png">
<meta property="og:image" content="http://yoursite.com/.com//120.png">
<meta property="og:image" content="http://yoursite.com/.com//121.png">
<meta property="og:image" content="http://yoursite.com/.com//122.png">
<meta property="og:image" content="http://yoursite.com/.com//123.png">
<meta property="og:image" content="http://yoursite.com/.com//124.png">
<meta property="og:image" content="http://yoursite.com/.com//125.png">
<meta property="og:image" content="http://yoursite.com/.com//126.png">
<meta property="og:image" content="http://yoursite.com/.com//127.png">
<meta property="og:image" content="http://yoursite.com/.com//128.png">
<meta property="og:image" content="http://yoursite.com/.com//129.png">
<meta property="og:image" content="http://yoursite.com/.com//130.png">
<meta property="og:image" content="http://yoursite.com/.com//131.png">
<meta property="og:image" content="http://yoursite.com/.com//132.png">
<meta property="og:image" content="http://yoursite.com/.com//133.png">
<meta property="og:image" content="http://yoursite.com/.com//134.png">
<meta property="og:image" content="http://yoursite.com/.com//135.png">
<meta property="og:image" content="http://yoursite.com/.com//136.png">
<meta property="og:image" content="http://yoursite.com/.com//137.png">
<meta property="og:image" content="http://yoursite.com/.com//138.png">
<meta property="og:image" content="http://yoursite.com/.com//139.png">
<meta property="og:image" content="http://yoursite.com/.com//140.png">
<meta property="og:image" content="http://yoursite.com/.com//141.png">
<meta property="og:image" content="http://yoursite.com/.com//142.png">
<meta property="og:image" content="http://yoursite.com/.com//143.png">
<meta property="og:image" content="http://yoursite.com/.com//144.png">
<meta property="og:image" content="http://yoursite.com/.com//145.png">
<meta property="og:image" content="http://yoursite.com/.com//146.png">
<meta property="og:image" content="http://yoursite.com/.com//153.png">
<meta property="og:image" content="http://yoursite.com/.com//147.png">
<meta property="og:image" content="http://yoursite.com/.com//148.png">
<meta property="og:image" content="http://yoursite.com/.com//151.png">
<meta property="og:image" content="http://yoursite.com/.com//152.png">
<meta property="og:image" content="http://yoursite.com/.com//149.png">
<meta property="og:image" content="http://yoursite.com/.com//150.png">
<meta property="og:image" content="http://yoursite.com/.com//154.png">
<meta property="og:image" content="http://yoursite.com/.com//155.png">
<meta property="og:image" content="http://yoursite.com/.com//156.png">
<meta property="article:published_time" content="2020-07-05T11:30:52.000Z">
<meta property="article:modified_time" content="2020-07-05T11:32:17.339Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/.com//1.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习之基础篇" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87/" class="article-date">
  <time datetime="2020-07-05T11:30:52.000Z" itemprop="datePublished">2020-07-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习之基础篇
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="机器学习（基础理论篇）"><a href="#机器学习（基础理论篇）" class="headerlink" title="机器学习（基础理论篇）"></a>机器学习（基础理论篇）</h1><p><a href="https://www.coursera.org/learn/machine-learning/home/welcome" target="_blank" rel="noopener">https://www.coursera.org/learn/machine-learning/home/welcome</a></p>
<p>机器学习可分为监督学习和无监督学习</p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>在监督学习中，我们已经被告知了什么是所谓的正确答案。即下面例子中的良性和恶性。</p>
<h3 id="回归问题（预测连续的数值输出）"><a href="#回归问题（预测连续的数值输出）" class="headerlink" title="回归问题（预测连续的数值输出）"></a>回归问题（预测连续的数值输出）</h3><p>例子：房屋价格预测</p>
<p><img src="/.com//1.png" alt></p>
<h4 id="线性回归算法"><a href="#线性回归算法" class="headerlink" title="线性回归算法"></a>线性回归算法</h4><p>也就是根据已有的样本拟合一条直线，用线性方程（一次函数）表示（称为假设函数）。如何拟合（设置参数）这个假设函数是重点。方程中的参数称为模型参数。</p>
<img src="/.com//5.png">

<p>m represents Number of training examples</p>
<p>x represents input variable/features</p>
<p>y represents output variable/‘target’ variable</p>
<p>代价函数（总是一个凹形函数）</p>
<p><img src="/.com//6.png" alt></p>
<p>我们通过改变这两个参数，让代价函数取到最小值，此时的假设函数能最好拟合实际情况。</p>
<h5 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h5><p>我们用梯度下降算法将代价函数最小化，公式为：</p>
<p><img src="/.com//7.png" alt></p>
<p>a称为学习速率。用来控制当梯度下降时，我们迈出多大的步子。a越大，梯度下降就越迅速。 化简上式得：</p>
<p><img src="/.com//8.png" alt></p>
<h4 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h4><p>实际情况当我们的参数很多时（比如在预测房价时，参数不只有面积，还有房屋年龄，卧室数量，地理位置…我们就要进行多元线性回归，这部分会用到线性代数的知识）</p>
<p><img src="/.com//9.png" alt></p>
<p>Tips 1</p>
<p>将x均值归一化（特征收敛），使这些x都处于某个较小的范围，这样后面当我们用梯度下降算法时就可以更快的找到那个最佳点。</p>
<p><img src="/.com//10.png" alt></p>
<p>Tips 2</p>
<p>如何选择学习率a</p>
<p>a过小会导致迭代次数过多</p>
<p>a过大会导致代价函数不收敛，甚至发散。</p>
<p>a取0.001，0.003，0.01，0.03，0.1，0.3，1，3…十倍的取，去看代价函数的值随迭代次数变化的情况（当我们判断代价函数此时收敛时，迭代次数越少，说明此时选择的a就越适合）找到合适的a。</p>
<p><img src="/.com//11.png" alt></p>
<p>上图当迭代次数为300左右时，代价函数就已经很好的收敛了。</p>
<h5 id="用正规方程求参数（不同于梯度下降算法）"><a href="#用正规方程求参数（不同于梯度下降算法）" class="headerlink" title="用正规方程求参数（不同于梯度下降算法）"></a>用正规方程求参数（不同于梯度下降算法）</h5><p>这种方法不需要进行tips 1 .</p>
<p>例子：</p>
<p><img src="/.com//14.png" alt></p>
<p>当X的转置*X不可逆时，我们就不能算出参数。通常出现这种情况是由于以下两个原因：</p>
<p>1.两个成倍数的特征值（删掉其中一个）</p>
<p>2.特征值太多，数量多于样本数（删掉一些）</p>
<p><img src="/.com//15.png" alt></p>
<p>对比</p>
<p><img src="/.com//13.png" alt></p>
<h4 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h4><p>有时我们的假设函数为二次函数或多次函数才能很好拟合：</p>
<p><img src="/.com//12.png" alt></p>
<h3 id="分类问题（预测一个离散的数值输出）"><a href="#分类问题（预测一个离散的数值输出）" class="headerlink" title="分类问题（预测一个离散的数值输出）"></a>分类问题（预测一个离散的数值输出）</h3><p>例子：预测肿瘤是良性还是恶性</p>
<p><img src="/.com//2.png" alt></p>
<p>当有多个特征值（age，size）时：</p>
<p>（o代表良性，x代表恶性）</p>
<p><img src="/.com//3.png" alt></p>
<p>实际上机器学习甚至可以设计一种算法处理无穷多个特征值的算法。</p>
<h4 id="logistic回归（一种分类算法）"><a href="#logistic回归（一种分类算法）" class="headerlink" title="logistic回归（一种分类算法）"></a>logistic回归（一种分类算法）</h4><p>算法的输出值会一直介于0到1之间</p>
<p>如下图</p>
<p>Sigmoid/Logistic 函数：g(z)</p>
<p>在logistic回归中假设函数的表示方法：</p>
<p>假设函数也可看作输入以θ为参数的x时，假设输出y=1的概率。</p>
<p>当g(z)大于等于0.5（z大于等于0）时，假设函数预测为1。</p>
<p>当g(z)小于0.5（z小于0）时，假设函数预测为0。</p>
<p>z其实就是我们之前回归问题中的假设函数。</p>
<p><img src="/.com//16.png" alt></p>
<p>假如现在我们已经拟合出了参数θ1  θ2   …</p>
<p>下图中的那条粉色线被称为决策边界，粉线右边输出为1，左边为0；它是假设函数的一个属性。</p>
<p><img src="/.com//17.png" alt></p>
<p>如果我们的数据集是这样的：</p>
<p><img src="/.com//18.png" alt></p>
<p>我们可以在假设函数中添加高阶多项式。假如现在我们已经拟合出了参数θ1  θ2   …，可以看到现在的决策边界是一个圆。这说明决策边界可以是更复杂的曲线，取决于我们假设函数。</p>
<p><img src="/.com//19.png" alt></p>
<p>如何拟合参数θ</p>
<p>先介绍一下代价函数。在logistic回归中，如果只有一个训练样本，我们的代价函数是这样的：</p>
<p>当y=1时，如下图，假如假设函数算出来的值也是1，则把1代到代价函数-log(1)中，此时代价为0。若假设函数趋于0，则代价为无穷大。</p>
<p><img src="/.com//20.png" alt></p>
<p>代价函数图象的推导：</p>
<p><img src="/.com//21.png" alt></p>
<p>红线部分 自变量x(这里就是我们的代价函数)范围0到1，y再取负值则沿x轴翻转，就得到代价函数的图像。</p>
<p>当y=0时，如下图</p>
<p><img src="/.com//22.png" alt></p>
<p>我们把单个样本代价函数用一个式子表示:</p>
<p><img src="/.com//23.png" alt></p>
<p>现在，当有多个样本时，我们真正的代价函数可以表示为：</p>
<p><img src="/.com//24.png" alt></p>
<p>与之前一样，用梯度下降算法，我们不断改变θ（改变θ要同时改变θ1，θ2…)，找到代价函数的最小值，这时的θ就是最佳的。</p>
<p><img src="/.com//7.png" alt></p>
<p>可以看到求出来的更新θj的式子与线性回归中的一样！</p>
<p><img src="/.com//25.png" alt></p>
<p>同样的，我们也可以把特征缩放的方法用在这里，让梯度下降收敛更快。</p>
<h4 id="多类别问题"><a href="#多类别问题" class="headerlink" title="多类别问题"></a>多类别问题</h4><p>如果有多种类别，例如三种时，如下图所示：</p>
<p>这时我们的解决方法是把最初的训练集分成三种情况，求出这三个训练集各自的假设函数。我们给出一个新的x值，代到这三个假设函数中，得到的值（概率）最大的那个就是我们应该选择的类别。</p>
<p><img src="/.com//26.png" alt></p>
<h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>过拟合是指我们的假设函数能够很好的拟合现有的数据集，但我们用了太多的特征（x）去拟合它，当有新的样本时并不能推测出一个合适的输出值。在回归问题和分类问题中都有可能会出现。如下图所示，右一就是过拟合的情况</p>
<p><img src="/.com//27.png" alt></p>
<h4 id="解决方法（对于线性回归问题）："><a href="#解决方法（对于线性回归问题）：" class="headerlink" title="解决方法（对于线性回归问题）："></a>解决方法（对于线性回归问题）：</h4><ol>
<li><p>减少特征数量（人工剔除或用算法自动剔除）</p>
</li>
<li><p>正则化：保留所有的特征，但把其中一些参数θj的值减小，让一些特征值的作用变小。</p>
<h5 id="将正则化用于梯度下降算法中"><a href="#将正则化用于梯度下降算法中" class="headerlink" title="将正则化用于梯度下降算法中"></a>将正则化用于梯度下降算法中</h5><p>右边的那项为正则化项 ，λ为正则化参数。</p>
<p><img src="/.com//28.png" alt></p>
</li>
</ol>
<p>对于θ0，按我们前面的说法是一个常数，因为x0我们默认为1。没有必要进行正则化。</p>
<p>对于其他的θj，每次变化的表达式依然是求偏导，只不过现在多了一项。整理式子后我们发现θj的表达式中，（1-a*λ/m）是略小于1的，因为一般m很大。这说明在添加正则项后，每次θ都会再变小一点点。</p>
<p><img src="/.com//29.png" alt></p>
<h5 id="将正则化用于正规方程中："><a href="#将正则化用于正规方程中：" class="headerlink" title="将正则化用于正规方程中："></a>将正则化用于正规方程中：</h5><p>θ新的表达式如下：（这里不再具体推导多的那一项是怎么来的，矩阵为(n+1)行*(n+1)列）</p>
<p><img src="/.com//30.png" alt></p>
<p>如果λ&gt;0，我们可以确保括号里的那一项是可逆的。</p>
<h4 id="解决方法（对于逻辑回归问题）："><a href="#解决方法（对于逻辑回归问题）：" class="headerlink" title="解决方法（对于逻辑回归问题）："></a>解决方法（对于逻辑回归问题）：</h4><p>与在线性回归问题中处理梯度下降算法的过拟合类似</p>
<p><img src="/.com//31.png" alt></p>
<p><img src="/.com//32.png" alt></p>
<h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p>当特征值很多时，前面学的算法会难以处理，因为计算量过大。此时我们会用神经网络模型。</p>
<p>神经网络模型会模拟人类大脑处理信息的方式，一个神经元接收一些信息（多个输入）并进行处理后，将输出传递给下一个神经元。输出用一个假设函数表示。假设函数中的参数在一些文献中也叫做weights权重。</p>
<p>下图中x0称为偏执单元，视情况决定是否添加。橙圈为一个神经元。<img src="/.com//33.png" alt></p>
<p>神经网络：</p>
<p>第一层叫输入层（input layer），第二层叫隐藏层（hidden layer，可以有多层，隐藏层每一项称为单元，它们的输出称为激活项），第三层叫输出层（output layer）。</p>
<p><img src="/.com//34.png" alt></p>
<p>前向传播</p>
<p>下图中g(z)就是sigmoid函数。权重矩阵为三行四列。一般来说，如果一个网络第j层有sj个单元，在j+1层有s(j+1)个单元，则θj的维度为s(j+1)行sj+1列。</p>
<p><img src="/.com//35.png" alt></p>
<h4 id="例1（非线性分类）"><a href="#例1（非线性分类）" class="headerlink" title="例1（非线性分类）"></a>例1（非线性分类）</h4><p>如果我们想要得到这样一个假设函数（实现非线性分类问题），当两个输入相同时，分为一类，当两个输入不同时，分为另一类。如下图所示</p>
<p><img src="/.com//40.png" alt></p>
<p>首先先用神经网络算法实现与操作</p>
<p>如果有三个特征值（x0默认为1），设参数为-30，20，20。x1和x2取值范围为0或1，假设函数就是g(-30+20X1+20X2)，现在进行检验，输入四种组合，我们的假设函数都能得到正确的结果。</p>
<p><img src="/.com//36.png" alt></p>
<p>或操作：</p>
<p><img src="/.com//37.png" alt></p>
<p>非操作：</p>
<p><img src="/.com//38.png" alt></p>
<p>将前面几种操作组合起来，就得到我们想要的实现。</p>
<p><img src="/.com//39.png" alt></p>
<h4 id="例2（多元分类）"><a href="#例2（多元分类）" class="headerlink" title="例2（多元分类）"></a>例2（多元分类）</h4><p>我们想要判断一张图片是行人，汽车，摩托还是货车。理想情况下，我们希望假设函数输出四种结果，每种结果分别对应行人，汽车…如下图</p>
<p><img src="/.com//41.png" alt></p>
<h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>根据训练集，从第一层到最后一层去构造每层假设方程的参数。</p>
<p><img src="/.com//42.png" alt></p>
<h5 id="表示代价函数"><a href="#表示代价函数" class="headerlink" title="表示代价函数"></a>表示代价函数</h5><p>我们用的是逻辑回归的代价函数的一般形式（输出有多种可能时）。</p>
<p>如下图所示。K个输出单元（可以看作假设函数的输出是一个k维向量），这里有四个；h(x)i指输出向量中的第几个；m个样本；L层，这里有四层；Sl表示第l层有S个单元。正则项可以理解为第l层中，第j个单元第i个参数θji的平方（一列一列的把参数依次加起来）。从前文可知，在第l层，θ参数可以看作一个矩阵，由i和j来标识。这里我们依然不加入偏差项(i=0项)</p>
<p><img src="/.com//43.png" alt></p>
<h5 id="用反向传播算法求代价函数的偏导项"><a href="#用反向传播算法求代价函数的偏导项" class="headerlink" title="用反向传播算法求代价函数的偏导项"></a>用反向传播算法求代价函数的偏导项</h5><p><img src="/.com//45.png" alt></p>
<p>现在先来看看只有一个样本集的情况，a表示激活值（一个向量）：</p>
<p><img src="/.com//46.png" alt></p>
<p>我们先表示一个激活值（不考虑第一层，每个激活值都是最开始的输入通过一或多次的g(z)函数得出来的输出）的代价（误差），<img src="/.com//47.png" alt>代表第l层第j个节点的误差。</p>
<p>从最后一层反向将前一层的代价（最后一层为假设的输出值与样本y值之差）表示出来。所有的代价相加就等于代价函数对θ求偏导的值。</p>
<p><img src="/.com//48.png" alt></p>
<p>当有m个样本集时：</p>
<p>用循环把每个样本的误差加一起。</p>
<p><img src="/.com//49.png" alt></p>
<p>注意！对于反向传播，我们用随机取值的方法将参数初始化。如下图：</p>
<p><img src="/.com//52.png" alt></p>
<p>反向传播算法的缺点：</p>
<p>容易出现一些无法被程序识别的小bug，即使我们观察到代价函数是逐渐减小的，但最终的结果可能会比正确的结果高出一个量级。</p>
<p>解决办法：</p>
<h5 id="梯度检验"><a href="#梯度检验" class="headerlink" title="梯度检验"></a>梯度检验</h5><p>当θ为一个实数时，让对θ的导数近似等于对θ的双侧差分</p>
<p><img src="/.com//51.png" alt></p>
<p>当θ为一个n维向量时，让对每个θ的偏导等于它们各自的双侧差分<img src="/.com//50.png" alt></p>
<p>之后我们验证通过梯度检验算出的代价函数的偏导是否近似等于反向传播算出来的偏导。如果很接近则说明反向传播是正确运行的，在正式运行代码时要关掉梯度检验，因为它梯度检验的运行速度很慢。</p>
<h5 id="神经网络模型总述"><a href="#神经网络模型总述" class="headerlink" title="神经网络模型总述"></a>神经网络模型总述</h5><p>1.选择一个合适的神经网络结构</p>
<p><img src="/.com//53.png" alt></p>
<p>2.将参数初始化。</p>
<p>3.用前向传播获得假设函数。</p>
<p>4.通过代码计算代价函数。</p>
<p>5.用反向传播算法计算各个参数的偏导</p>
<p>6.用梯度检验确定反向传播算法没问题后，关闭梯度检验（如下图）</p>
<p>7.知道偏导后就可以用梯度下降算法或其他高级算法更新θ，逐渐找到代价函数的局部最小值。</p>
<p><img src="/.com//55.png" alt></p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><h4 id="选择多项式（选择模型）"><a href="#选择多项式（选择模型）" class="headerlink" title="选择多项式（选择模型）"></a>选择多项式（选择模型）</h4><p>将样本集分为训练集，(交叉)验证集和测试集（比例为3:1:1）：</p>
<p><img src="/.com//57.png" alt></p>
<p>三个集合各自的代价函数的表示：</p>
<p><img src="/.com//58.png" alt></p>
<p>如下图所示，假如有10个待选模型。我们先用验证集的数据确定参数，再算出这10个代价函数的值（比较大小），选择哪个假设函数是最优的，假如第五个模型是最优的。以这个最优模型的参数为参考，去人工调整训练集模型的参数。</p>
<p>在不断调整训练集的模型的过程中，我们用测试集（相当于新样本）去测试模型的泛化误差。</p>
<p><img src="/.com//59.png" alt></p>
<h4 id="如何判断偏差欠拟合与方差过拟合"><a href="#如何判断偏差欠拟合与方差过拟合" class="headerlink" title="如何判断偏差欠拟合与方差过拟合"></a>如何判断偏差欠拟合与方差过拟合</h4><p>当偏差过大时为欠拟合，当方差过大时为过拟合。</p>
<p>一开始，训练误差与验证误差一开始都很大，此时为欠拟合。随着假设函数多项式次数的增加，训练误差变得很小，而验证误差远远大于训练误差，此时为过拟合。</p>
<p><img src="/.com//60.png" alt></p>
<h4 id="正则化与欠拟合、过拟合的关系"><a href="#正则化与欠拟合、过拟合的关系" class="headerlink" title="正则化与欠拟合、过拟合的关系"></a>正则化与欠拟合、过拟合的关系</h4><p>λ越大，对参数的惩罚程度越大，欠拟合程度越高。</p>
<p>λ越小，对参数的惩罚程度越小，过拟合程度越高。</p>
<p><img src="/.com//61.png" alt></p>
<p>如何选择正则化参数λ：</p>
<p>尝试一组λ，找出其中使验证误差最小的λ。</p>
<p><img src="/.com//62.png" alt></p>
<p>随λ的变化，训练误差与验证误差的变化如下：</p>
<p><img src="/.com//63.png" alt></p>
<h4 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h4><p>判断模型是否存在偏差或方差问题</p>
<p>m就找训练集中的大概10个20个就可以了。</p>
<p>正常情况下，我们假设模型是一个二次函数（这个训练集比较符合二次函数的特征）：</p>
<p>随着训练样本的增加，训练误差会越来越大。（样本少时能很好拟合，但样本多时二次函数可能就已经不足以拟合了）</p>
<p>而验证误差会越来越小，因为随着样本的增大，能获得更好的泛化表现。</p>
<p><img src="/.com//64.png" alt></p>
<p>高偏差时的学习曲线：</p>
<p>如果我们用一个一次函数作为假设函数：</p>
<p>随着训练样本的增加，训练误差会不断增大直到趋近一个稳定值。因为我们知道一次函数并不能很好的拟合这些样本，即使样本量越来越大。而验证误差会从一个很高的值逐渐减小直到趋近一个稳定值。最终两种误差值会比较接近。<img src="/.com//65.png" alt></p>
<p>高方差时的学习曲线：</p>
<p>当我们用一个高阶函数作为（模型）假设函数时：</p>
<p>随着样本量不断的增大，模型会变得越来越好。</p>
<p><img src="/.com//66.png" alt></p>
<p>因此如果出现过拟合问题，增大训练样本数量对改进算法是有帮助的。</p>
<h4 id="如何修正算法"><a href="#如何修正算法" class="headerlink" title="如何修正算法"></a>如何修正算法</h4><p>在了解过拟合和欠拟合之后。当得到一个线性回归模型但它的误差很大时，我们可以从以下方面去修正这个模型（修正欠拟合或过过拟合）：</p>
<p><img src="/.com//56.png" alt></p>
<h4 id="对于神经网络的欠拟合和过拟合"><a href="#对于神经网络的欠拟合和过拟合" class="headerlink" title="对于神经网络的欠拟合和过拟合"></a>对于神经网络的欠拟合和过拟合</h4><p>通常隐藏层越多，每层单元越多（计算量也就越大），就意味着参数越多，更容易出现过拟合。我们可以根据之前所说的将样本集划分为训练集，验证集，测试集来找最适合的那个模型结构。</p>
<h3 id="机器学习系统设计"><a href="#机器学习系统设计" class="headerlink" title="机器学习系统设计"></a>机器学习系统设计</h3><h4 id="执行的优先级"><a href="#执行的优先级" class="headerlink" title="执行的优先级"></a>执行的优先级</h4><p>例子：垃圾邮件分类器</p>
<p>如何让这个分类器错误率更小（随机选择以下的方法，因为不能确定哪一个效果更好）：</p>
<p><img src="/.com//68.png" alt></p>
<p>一开始时，先用一个尽量简单粗暴的模型去实现，之后再根据学习曲线去调整这个模型。同时，对于那些经常被错误分类的邮件，我们看看这些邮件内容它们有没有什么共同特征（误差分析），看是否还需要添加新的特征。</p>
<p>在决定要不要使用词干提取器（如Porter Stemmer，会将discount，discounts，discounting…看成一个）时，我们可以用交叉验证集的数据验证在使用它前后误差率的变化。</p>
<h4 id="不对称性分类的误差评估（度量率-召回率）"><a href="#不对称性分类的误差评估（度量率-召回率）" class="headerlink" title="不对称性分类的误差评估（度量率/召回率）"></a>不对称性分类的误差评估（度量率/召回率）</h4><p>例如我们想要设计一个模型判断是否是癌症，由于我们知道患病率本来就是很低的，所以对于那些验证集样本，我们不能接受一个相对高的误差率。（比如误差率是1%，而验证集样本的患病率是0.5%，说明这个模型不好。因为即使我们把所有样本都当成未患病的，误差率也只有0.5%。）</p>
<p>对于这种偏斜类，我们可以用度量率或召回率（越高越好）来度量误差</p>
<p>度量率：在验证集中，对于我们预测的那些患有癌症的病人，真正有多少个患有癌症的比率。</p>
<p>召回率：在验证集中，对于那些患有癌症的病人，我们预测正确的比率。</p>
<p><img src="/.com//69.png" alt></p>
<p>度量率和召回率的权衡</p>
<p>假如我们将假设函数的临界值设为0.7。假设值&gt;=0.7时预测为1，此时的度量率高，而召回率低。</p>
<p><img src="/.com//70.png" alt></p>
<p>用F1 Score值（0-1之间，越大越好）来度量：</p>
<p><img src="/.com//71.png" alt></p>
<h3 id="支持向量机（SVM）-大间距分类器"><a href="#支持向量机（SVM）-大间距分类器" class="headerlink" title="支持向量机（SVM）/大间距分类器"></a>支持向量机（SVM）/大间距分类器</h3><h4 id="推导代价函数"><a href="#推导代价函数" class="headerlink" title="推导代价函数"></a>推导代价函数</h4><p>在逻辑函数中，一个样本的代价函数表示为</p>
<p><img src="/.com//72.png" alt></p>
<p>（图左）当y=1时，代价函数替换为品红色线，用cost1(z)表示。</p>
<p>（图右）当y=0时，代价函数替换为品红色线，用cost0(z)表示。</p>
<p>用上面的两项代替逻辑回归代价函数函数表达式的那两项，去掉1/m（习惯），不再用λ参数而是C去权衡代价项和正则项的权重，就得到支持向量机的代价函数：</p>
<p><img src="/.com//73.png" alt></p>
<h4 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h4><p><img src="/.com//74.png" alt></p>
<h4 id="分析代价函数"><a href="#分析代价函数" class="headerlink" title="分析代价函数"></a>分析代价函数</h4><p>现在我们要使代价函数最小，根据图形可知</p>
<p>如果y=1时，z&gt;=1代价函数就最小（我们知道根据假设函数z&gt;=0时就能够正确分类）。（通常参数C会选取的很大）</p>
<p><img src="/.com//75.png" alt></p>
<p>SVM决策边界：</p>
<p><img src="/.com//76.png" alt></p>
<p>举例</p>
<p>黑色线就是向量机的决策边界（黑色线到正/负样本的距离称为间距，它比起其他线间距是最大的），相比其他的决策边界，它的鲁棒性更强，适用性也更好。</p>
<p><img src="/.com//77.png" alt></p>
<h4 id="高斯核函数exp"><a href="#高斯核函数exp" class="headerlink" title="高斯核函数exp()"></a>高斯核函数exp()</h4><p>用于在向量机中定义新的特征变量，获得更加复杂精确的决策边界。</p>
<p><img src="/.com//80.png" alt></p>
<p>假如我们用特征值x1，x2构造三个新特征f1，f2，f3。手动选择三个标记点。这里的exp()就是核函数，确切来说是高斯核函数。</p>
<p><img src="/.com//81.png" alt></p>
<p>σ的作用：</p>
<p>如果标记点在[3,5]，当x为[3,5]时，f1位于最高点</p>
<p><img src="/.com//78.png" alt></p>
<p>每个标记点l对应一个f</p>
<p><img src="/.com//82.png" alt></p>
<p>来看看核函数是怎么预测输出的：</p>
<p>这里假设x是二维（两个特征值x1，x2）</p>
<p>三个特征变量f1，f2，f3，假如现在我们有三个标记点，且已经知道参数的值（下图所示）。与之前一样，当假设函数&gt;=0时，预测输出值为1。</p>
<p>现在如果有一个样本（x1,x2），靠近l1（品红色部分），那么根据核函数定义假设函数的值&gt;=0，预测输出为1。如果一个样本靠近三个标记点的任意一个，它都会被预测为1。通过这种方式我们就可以得到一条橘红的非线性的决策边界，内部预测为1，外部预测为0。</p>
<p><img src="/.com//79.png" alt></p>
<p>如何选取标记点l</p>
<p>将标记点直接选取为样本的位置</p>
<p><img src="/.com//83.png" alt></p>
<p>（对于特征值x1，x2…，如果x1是房屋面积(例如1000平米)，x2是卧室的数量，它们的值差异很大，我们需要把x1缩放，以免||x-l||^2都由房屋面积决定，让SVM能考虑到所有特征变量f。）</p>
<p>f作为新的特征向量</p>
<p><img src="/.com//84.png" alt></p>
<p>引入核函数之后的向量机的代价函数：</p>
<p>需要注意的是，在实际操作中，如果参数特别多时，我们计算θ^2(等同于[θ]^T[θ])时，会改为计算[θ]^TM[θ]，M为一个矩阵，与标记点有关。这样是为了简化计算。</p>
<p><img src="/.com//85.png" alt></p>
<p>参数大小的选择</p>
<p><img src="/.com//86.png" alt></p>
<h4 id="线性核函数"><a href="#线性核函数" class="headerlink" title="线性核函数"></a>线性核函数</h4><p>线性核函数为K(x,z)=xTz。</p>
<h4 id="向量机vs逻辑回归vs神经网络"><a href="#向量机vs逻辑回归vs神经网络" class="headerlink" title="向量机vs逻辑回归vs神经网络"></a>向量机vs逻辑回归vs神经网络</h4><h2 id><a href="#" class="headerlink" title></a><img src="/.com//87.png" alt></h2><h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>我们只知道有一堆数据（x），但并不了解什么是正确答案（输出y）。</p>
<p>无监督学习算法–聚类算法可以判定这个数据集包含两个簇</p>
<p><img src="/.com//4.png" alt></p>
<p>例子：谷歌新闻收集某个事件所有报道，就是搜索成千上万个新闻，把与这个事件有关的新闻都分为一簇。</p>
<h3 id="聚类算法–K-means"><a href="#聚类算法–K-means" class="headerlink" title="聚类算法–K-means"></a>聚类算法–K-means</h3><h4 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h4><p>1.随机生成两个点–聚类中心</p>
<p>2.簇分配</p>
<p>遍历每个样本，离哪个聚类中心更近就把它们分为哪一簇</p>
<p><img src="/.com//88.png" alt></p>
<p>3.移动聚类中心</p>
<p>将红色的聚类中心移至红点的均值处，蓝色的聚类中心作相同操作。</p>
<p><img src="/.com//89.png" alt></p>
<p>4.重复操作</p>
<p>移动聚类中心后，再次检查这些样本，看它们离哪个聚类中心更近，就分配给那个簇。</p>
<p><img src="/.com//90.png" alt></p>
<p>之后再次计算这两个簇的均值，并将各自的聚类中心移至新的均值处。</p>
<p><img src="/.com//91.png" alt></p>
<p>按照新的聚类中心，重新将样本分簇。</p>
<p><img src="/.com//92.png" alt></p>
<p>现在k均值已经聚合了，即聚类中心和簇已经固定了。</p>
<h4 id="K均值算法的一般表示"><a href="#K均值算法的一般表示" class="headerlink" title="K均值算法的一般表示"></a>K均值算法的一般表示</h4><p>两个输入：</p>
<p>一是簇的个数，K个</p>
<p>二是样本（m个样本，每个样本的特征值为n个）</p>
<p><img src="/.com//93.png" alt></p>
<p>随机初始化K个聚类中心</p>
<p>c^(i)=2表示第i个样本属于簇2</p>
<p>遍历m个样本，对于第i个样本，找出它离哪个聚类中心最近，就把它分配给这个聚类中心（如果某个聚类中心没有被分配到样本，我们一般会直接移除，或者重新分配一个聚类中心）。之后再把K个簇的样本分别求均值，作为新的聚类中心。重复以上步骤直到结果聚合为止。</p>
<p><img src="/.com//94.png" alt></p>
<h4 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h4><p>样本到它们各自的聚类中心距离的平方的均值的最小值。</p>
<p><img src="/.com//95.png" alt></p>
<p>簇分配与移动聚类中心的过程其实就是在最小化代价函数J</p>
<h4 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h4><p>如何初始化聚类中心，使算法避开局部最优：</p>
<p>1，K应该&lt;M</p>
<p>2，一开始时，随机选择K个样本作为聚类中心。</p>
<p><img src="/.com//96.png" alt></p>
<p>聚类中心初始化的不同与导致最终的结果不同，可能会落在局部最优。如下图所示</p>
<p><img src="/.com//97.png" alt></p>
<p>为了让最终的结果是全局最优或者一个比较好的局部最优，我们可以尝试多次随机初始化，比较最终的结果。</p>
<p>具体步骤：</p>
<p>例如我们进行100次聚类算法操作，比较最终得到的100个代价函数，选择最小的那个。通常簇的数量小时多次随机初始化会更有效。</p>
<p><img src="/.com//98.png" alt></p>
<p>选择簇的数量</p>
<p>1.运用肘部法则</p>
<p>缺点：一些情况可能并不能得到一个清晰的拐点</p>
<p><img src="/.com//99.png" alt></p>
<p>2.根据我们的目的来决定数量</p>
<p>例如我们可以将人们衣服的尺寸分为3类（S,M,L)或者是5类（XS,S,M,L,XL)，这就意味着簇的数量为3个或者5个。</p>
<p><img src="/.com//100.png" alt></p>
<h3 id="降维算法–PCA"><a href="#降维算法–PCA" class="headerlink" title="降维算法–PCA"></a>降维算法–PCA</h3><p>1.用于数据压缩（减小内存，加速学习算法）</p>
<p>有时如果两个特征高度相关（例如厘米和英寸，可能由于四舍五入的原因它们没有完全成正比），则将这个二维特征降为一维（变成一个新的特征值）。</p>
<p><img src="/.com//101.png" alt>2.用于可视化数据</p>
<p>通常将数据降为2维或3维</p>
<h4 id="PCA–主成分分析算法"><a href="#PCA–主成分分析算法" class="headerlink" title="PCA–主成分分析算法"></a>PCA–主成分分析算法</h4><p>首先将x1,x2，…xn进行均值归一化（使n个特征值的均值相加为0）和特征规范化。</p>
<p>Sj是特征j的标准偏差</p>
<p><img src="/.com//104.png" alt></p>
<p>找到一个投影平面（一维或多维，看需求）对数据进行投影，使这些数据到这个平面的距离最短。</p>
<p><img src="/.com//102.png" alt></p>
<p>PCA不是线性回归</p>
<p><img src="/.com//103.png" alt></p>
<p>左边是线性回归，右边是PCA.。</p>
<h4 id="获取降维后的特征值"><a href="#获取降维后的特征值" class="headerlink" title="获取降维后的特征值"></a>获取降维后的特征值</h4><p>如何将n维特征值减少到k维</p>
<p>1.首先计算sigma矩阵即协方差矩阵（n*n），不要X0</p>
<p>2.将sigma矩阵进行奇异值分解(svd表示奇异值分解)</p>
<p>3.在U矩阵n<em>n中提取前k个向量,减小后的U矩阵为n</em>k</p>
<p><img src="/.com//105.png" alt></p>
<p>4.得到映射后的k维特征值Z(i)（k行*1列）。最初的X为n维。</p>
<p><img src="/.com//106.png" alt></p>
<p>（这里不进行数学证明为什么通过上述步骤就可以进行数据降维，以为证明过程超出了目前的学习范围）</p>
<h4 id="如何选取参数K"><a href="#如何选取参数K" class="headerlink" title="如何选取参数K"></a>如何选取参数K</h4><img src="/.com//110.png" style="zoom:67%;">

<p>原始数据的重构(reconstruction),将z还原到x：</p>
<img src="/.com//109.png" style="zoom:67%;">

<p>调整k使得99%的方差被保留。0.01可以按照需求进行调整。</p>
<p><img src="/.com//107.png" alt></p>
<p>下图左方框中的值等价于图右中进行svd后对S矩阵的操作</p>
<p><img src="/.com//108.png" alt></p>
<h4 id="用PCA加速监督学习算法"><a href="#用PCA加速监督学习算法" class="headerlink" title="用PCA加速监督学习算法"></a>用PCA加速监督学习算法</h4><p><img src="/.com//111.png" alt></p>
<p>PCA只能在训练集上运行，当定义了x到z的映射后，才可以把这个映射运用到验证集和测试集中。</p>
<h4 id="PCA不能用于处理过拟合"><a href="#PCA不能用于处理过拟合" class="headerlink" title="PCA不能用于处理过拟合"></a>PCA不能用于处理过拟合</h4><p>尽管PCA似乎减少了特征值，但这个过程并没有使用到y值，可能会舍弃一些有价值的信息。</p>
<p><img src="/.com//112.png" alt></p>
<p>此外，在设计一个机器学习系统时，也不要过多的滥用PCA,即使一开始有大量的特征值，先考虑能否直接实现</p>
<p><img src="/.com//113.png" alt></p>
<h3 id="异常检测算法"><a href="#异常检测算法" class="headerlink" title="异常检测算法"></a>异常检测算法</h3><p>假设那些红色标记的引擎是正常的，现在检测一个新的飞机引擎是否有异常：</p>
<p><img src="/.com//114.png" alt></p>
<p>更普遍来说</p>
<p>根据训练样本(都是正常的)，建立概率模型p(x)。如果测试样本的概率p(X test)小于某个设定的阈值，就认为这个测试样本是异常的。</p>
<p><img src="/.com//115.png" alt></p>
<h4 id="正态分布（高斯分布）"><a href="#正态分布（高斯分布）" class="headerlink" title="正态分布（高斯分布）"></a>正态分布（高斯分布）</h4><p>根据满足正态分布的这些样本计算两个参数：均值和方差。知道这两个参数就能画出图。</p>
<p><img src="/.com//116.png" alt></p>
<h4 id="用正态分布推异常检测算法"><a href="#用正态分布推异常检测算法" class="headerlink" title="用正态分布推异常检测算法"></a>用正态分布推异常检测算法</h4><p>现在有m个样本，n个特征量，每个特征量（独立的，不是也没关系）都服从高斯分布。计算出每个特征量各自的的高斯分布（也就是计算均值，方差），最后根据p(x)=p(x1,x2,…xn)=p(x1)p(x2)…p(xn)计算p(x)。</p>
<p><img src="/.com//117.png" alt></p>
<p>假如现在有两个特征量</p>
<p><img src="/.com//118.png" alt></p>
<h4 id="例子–飞机引擎异常检测"><a href="#例子–飞机引擎异常检测" class="headerlink" title="例子–飞机引擎异常检测"></a>例子–飞机引擎异常检测</h4><p>假设有10000个好的引擎，40个坏的。（这里其实这些样本都是有标签的），像以前一样把它们分成三种样本。</p>
<p><img src="/.com//119.png" alt></p>
<p>用训练集得到这个异常检验算法后，用验证集进行检验，由于数据很倾斜(y=0的结果很常见)，我们用精确度或召回率（前文有）来判断这是不是一个好的模型。</p>
<p>在验证集上选择ε（找一组），看哪个ε对应的F1-score值最大；或者决定要不要舍弃某个特征值。</p>
<p><img src="/.com//120.png" alt></p>
<p>最后再用测试集进行最终的测试。</p>
<h4 id="异常检测-vs-监督学习"><a href="#异常检测-vs-监督学习" class="headerlink" title="异常检测 vs 监督学习"></a>异常检测 vs 监督学习</h4><p>既然我们的样本都是带有标签的，那为什么不能用逻辑回归或者神经网络去检测异常。</p>
<p>因为对于一些例子positive样本很少很少，而negative样本很多（比如飞机引擎10000个可能只有20个坏的），我们很难通过学习监督学习的算法去找到那些positive样本的规律。</p>
<p><img src="/.com//121.png" alt></p>
<p>选择特征</p>
<p>当某个特征值x不满足正太分布时，将它们高斯化（log(x)或x^1/2…）。</p>
<p><img src="/.com//122.png" alt></p>
<h4 id="如何选取特征"><a href="#如何选取特征" class="headerlink" title="如何选取特征"></a>如何选取特征</h4><p>与之前一样，当用训练样本得到异常检测模型后，用验证集输入到模型中，检查那些检测出错的样本，观察如何改动现有的特征值去更好的。</p>
<h4 id="多元高斯分布"><a href="#多元高斯分布" class="headerlink" title="多元高斯分布"></a>多元高斯分布</h4><p>一些情况下，高斯分布不能很好的检测异常。</p>
<p>如下图，我们知道蓝圈中的都是正常的样本，而高斯分布会使得粉圈上的样本概率都相同，这样本来一些异常的样本如果用高斯分布检测就会出错。（我认为这是因为x1，x2存在正相关的关系，并不是相互独立的）</p>
<p><img src="/.com//123.png" alt></p>
<p>此时的p(x)表示为</p>
<p><img src="/.com//124.png" alt></p>
<p>改变协方差矩阵</p>
<p><img src="/.com//125.png" alt></p>
<p><img src="/.com//126.png" alt></p>
<p><img src="/.com//127.png" alt></p>
<p><img src="/.com//128.png" alt></p>
<p>改变均值</p>
<p><img src="/.com//129.png" alt></p>
<p>参数拟合：</p>
<p>协方差矩阵与在PCA中的表示一样。</p>
<p><img src="/.com//130.png" alt></p>
<p>如何用多元高斯分布进行异常检测</p>
<p><img src="/.com//131.png" alt></p>
<h4 id="多元高斯-vs-高斯"><a href="#多元高斯-vs-高斯" class="headerlink" title="多元高斯 vs 高斯"></a>多元高斯 vs 高斯</h4><p><img src="/.com//132.png" alt></p>
<h3 id="推荐系统算法"><a href="#推荐系统算法" class="headerlink" title="推荐系统算法"></a>推荐系统算法</h3><p>例子：预测电影评分</p>
<p>对于那些已经评分的电影（r(i,j)=1表示用户j评价了电影i，y^(i,j)=1表示评分为1分。），我们想要预测用户如何对没看过的电影评分</p>
<p><img src="/.com//133.png" alt></p>
<h4 id="基于内容的推荐算法"><a href="#基于内容的推荐算法" class="headerlink" title="基于内容的推荐算法"></a>基于内容的推荐算法</h4><p>x1表示一部电影为爱情片的程度</p>
<p>x2表示一部电影为动作片的程度</p>
<p>每一部电影就可以用一组特征值表示（x0=1）（基于内容的含义）</p>
<p>每个用户各自的喜好用参数θ1，θ2…表示</p>
<p>假设函数（这里用线性方程）表示为θ1^T*X^(3)（如果预测用户1对电影3的评价）</p>
<p><img src="/.com//134.png" alt></p>
<p>m^(j)表示用户j评价的电影的数量</p>
<p>如何计算用户j的参数：</p>
<p>写出代价函数（与线性回归一样），为了方便这里不要m（不影响最终结果）</p>
<p><img src="/.com//135.png" alt></p>
<p>对于所有用户，代价函数为</p>
<p><img src="/.com//136.png" alt></p>
<h4 id="自行学习特征算法"><a href="#自行学习特征算法" class="headerlink" title="自行学习特征算法"></a>自行学习特征算法</h4><p>假如现在我们知道每个用户的喜好（θ），知道A和B喜好爱情电影，C和D不喜欢，喜换动作电影。那么根据他们对于电影的评分，我们就能够推测出那些电影是什么类型的（x）。例如对于第一部电影：</p>
<p><img src="/.com//137.png" alt></p>
<p>对于第i部电影，通过最小化代价函数找到它的特征值：</p>
<p><img src="/.com//138.png" alt></p>
<p>对于所有电影，代价函数为 ：</p>
<p><img src="/.com//139.png" alt></p>
<h4 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h4><p>将上文说到的两种算法结合起来。即我们只知道一些用户评分，就可以将用户的参数和电影的特征值都学习出来。</p>
<p>思想：我们先将参数随机初始化，然后算出特征值，再根据这些特征值，拟合出更好的参数…不断循环，直到算法已经可以很好的进行预测。</p>
<p>用于得到协调过滤算法的一种更好的方法，将两个代价函数结合起来，对所有有评分的用户-电影对代价进行求和，同时解出x和θ（不需要反复计算），这里不要x0：</p>
<p><img src="/.com//140.png" alt></p>
<h5 id="算法步骤总结"><a href="#算法步骤总结" class="headerlink" title="算法步骤总结"></a>算法步骤总结</h5><p><img src="/.com//141.png" alt></p>
<p>第三步中用户j和电影i都是我们学习过程中的对象，也就是我们只能对前面表格中的那些问号进行预测。</p>
<h5 id="协同过滤算法的应用"><a href="#协同过滤算法的应用" class="headerlink" title="协同过滤算法的应用"></a>协同过滤算法的应用</h5><p><img src="/.com//142.png" alt></p>
<p>写出预测矩阵</p>
<p>低秩矩阵（Xθ^T）分解</p>
<p><img src="/.com//143.png" alt></p>
<p>如果用户正在看电影i，如何找到与i相似的电影并推荐给用户：</p>
<p><img src="/.com//144.png" alt></p>
<h5 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h5><p>如果有一个新用户Eve，她没有对任何电影进行评价，如果按照常规的协同过滤算法算出的Eve的参数是一个0向量，那她的所有预测评分都是0 ，这样就不能给她推荐电影。</p>
<p><img src="/.com//145.png" alt></p>
<p>解决方法：</p>
<p>均值归一化指算出每一部电影分数的均值，客户对这部电影的评分减去均值，这样每一行（相加为0）。用户评分均值归一化后，再用协调过滤算法来学习特征值和参数。现在对某部电影的预测评分就还要加上那部电影评分的均值。因此Eve的预测评分就不再是0，而变成了均值。</p>
<p><img src="/.com//146.png" alt></p>
<h3 id="处理大数据集"><a href="#处理大数据集" class="headerlink" title="处理大数据集"></a>处理大数据集</h3><p>如果有几亿十几亿样本时，一般的梯度下降算法的计算量将会非常大。所以我们现在学习一些新的梯度下降算法</p>
<h4 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h4><p>每次迭代只需要一个样本，得到的代价函数会迭代到接近全局最小值，并在那里反复徘徊。一般我们将学习速率设置为一个常数（偶尔有些人会让a逐渐变小，这样越迭代越能精确到全局最小）</p>
<p><img src="/.com//153.png" alt></p>
<h5 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h5><p>1.随机打乱所有数据：将m个训练样本随机重新排列（能够更快收敛）</p>
<p>2.对训练样本一个一个的进行遍历，这样在更新θj时，我们可以把图左橘框中的求和项拆开，一次一次的改变θj而不是先把几亿个加起来。</p>
<p><img src="/.com//147.png" alt></p>
<p>如果m很大很大，很有可能只需要进行一次随机梯度下降就收敛了。一般Repeat的次数为1-10次。</p>
<p><img src="/.com//148.png" alt></p>
<h5 id="确保能正确收敛"><a href="#确保能正确收敛" class="headerlink" title="确保能正确收敛"></a>确保能正确收敛</h5><p>对于一般的梯度下降，如前文所说，我们通过绘制出代价函数随迭代次数变化的图像观察代价函数是否收敛。</p>
<p>对于随机梯度下降，我们计算1000次迭代的代价函数的平均值，绘制出代价函数的随着次数变化的图像观察。</p>
<p>!(机器学习（基础篇）\151.png)</p>
<p><img src="/.com//151.png" alt></p>
<p>如下图所示，</p>
<p>左上方橘线表示学习速率a更大时</p>
<p>右上方橘线表示算平均代价函数时选取的样本量更大时</p>
<p>左下方表示有时候噪声太大，选取1000个样本取平均函数看不出是在收敛，如果选取5000个（橘）时能看出是在缓慢收敛的</p>
<p>右下方表示代价函数发散了，要考虑选用更小的学习速率</p>
<p><img src="/.com//152.png" alt></p>
<h4 id="Mini-Batch梯度下降"><a href="#Mini-Batch梯度下降" class="headerlink" title="Mini-Batch梯度下降"></a>Mini-Batch梯度下降</h4><p>介于一般梯度下降和随机梯度下降之间，每次用b个样本进行迭代。b一般为2-100之间。例如b=10时：</p>
<p><img src="/.com//149.png" alt></p>
<p>如果有好的向量化方法同时计算10个样本，mini-batch梯度下降会比随机梯度下降更快。</p>
<p><img src="/.com//150.png" alt></p>
<p>在线学习机制</p>
<p>随机梯度下降的衍生</p>
<h5 id="例1"><a href="#例1" class="headerlink" title="例1"></a>例1</h5><p>例如我们有一个运输货物网站，有连续的数据流（客户访问）。客户输入起始地和目的地，我们给他们一个价格，看他们是否接受我们的运输服务。之后通过学习（这个例子使用逻辑回归，神经网络也可以）改变价格使其最优。</p>
<p>x包括起始地，目的地，价格，y为0或1（接受这个价格）</p>
<p>在得到一个样本(x,y)后，使用这个样本来更新参数，之后丢弃这个样本</p>
<p><img src="/.com//154.png" alt></p>
<p>所以在线学习算法可以适应用户偏好的变动</p>
<h5 id="例2-CTR–点击率学习问题"><a href="#例2-CTR–点击率学习问题" class="headerlink" title="例2 CTR–点击率学习问题"></a>例2 CTR–点击率学习问题</h5><p>学习用户点击某一个你提供给他们链接的概率。</p>
<p>当用户输入关键词时，返回10个搜索结果，即我们就得到了10个样本，然后用在线学习算法更新参数。之后丢弃这些样本。</p>
<p><img src="/.com//155.png" alt></p>
<p>Map-Reduce</p>
<p>当随机梯度下降都不能很好的减小计算时</p>
<p>假如我们有四台电脑，我们把样本（贤假设样本量只有400）分成4份。分别计算再将结果传给一个中心服务器进行整合。</p>
<p><img src="/.com//156.png" alt></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87/" data-id="ckc8zy8jj0001p8vt5tq51rdd" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2020/07/05/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87/">机器学习之基础篇</a>
          </li>
        
          <li>
            <a href="/2020/07/05/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>